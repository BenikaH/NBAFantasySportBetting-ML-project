{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Collect allplayerGameLogs by 3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from urllib import urlencode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../Data/playid_df.pickle','rb') as data_file:\n",
    "    playid_data = pickle.load(data_file)\n",
    "playid_df = pd.DataFrame(playid_data)\n",
    "ids_ls = playid_df['playerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collectAllPlayerGameLogs(ids_ls):\n",
    "    leagueid = '00'\n",
    "    url = \"http://stats.nba.com/stats/playergamelog?\"\n",
    "    u_a = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0'} #header is necessary\n",
    "    allplayerGameLogs_df_ls = []\n",
    "    season='2015-16'\n",
    "    seasontype='Regular Season'\n",
    "    \n",
    "    for playerid in ids_ls:\n",
    "        api_param = (('LeagueID', leagueid),('PlayerID',playerid),('Season',season),('SeasonType',seasontype))\n",
    "        response = requests.get(url, params=api_param,headers={\"USER-AGENT\":u_a})\n",
    "        response_json = response.json()\n",
    "        response_df = pd.DataFrame(response_json['resultSets'][0]['rowSet'],columns=response_json['resultSets'][0]['headers'])\n",
    "        allplayerGameLogs_df_ls.append(response_df)\n",
    "        \n",
    "    allplayerGameLogs_df = pd.concat(allplayerGameLogs_df_ls,axis=0)\n",
    "    return(allplayerGameLogs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20875, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allplayerGameLogs_0313 = collectAllPlayerGameLogs(ids_ls)\n",
    "allplayerGameLogs_0313.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/allplayerGameLogs_0313.pickle', 'wb') as handle:\n",
    "  pickle.dump(allplayerGameLogs_0313, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Munging to combine different data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allplayerGameLogs = allplayerGameLogs_0313\n",
    "del allplayerGameLogs_0313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleaner(allplayerGameLogs):\n",
    "    #data cleaning 1: add calculated Fantasy Points for each player in each game\n",
    "    allplayerGameLogs['GAME_DATE'] = pd.to_datetime(allplayerGameLogs['GAME_DATE'])\n",
    "    del allplayerGameLogs['VIDEO_AVAILABLE']\n",
    "    dd = ((allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['AST']>=10))| \\\n",
    "         ((allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['REB']>=10))| \\\n",
    "         ((allplayerGameLogs['AST']>=10) & (allplayerGameLogs['REB']>=10))| \\\n",
    "         ((allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['STL']>=10))| \\\n",
    "         ((allplayerGameLogs['REB']>=10) & (allplayerGameLogs['BLK']>=10))| \\\n",
    "         ((allplayerGameLogs['STL']>=10) & (allplayerGameLogs['BLK']>=10))| \\\n",
    "         ((allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['BLK']>=10))\n",
    "    allplayerGameLogs['DouBL']= dd\n",
    "    ttt = (allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['AST']>=10) & (allplayerGameLogs['REB']>=10)| \\\n",
    "          (allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['STL']>=10) & (allplayerGameLogs['REB']>=10)| \\\n",
    "          (allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['BLK']>=10) & (allplayerGameLogs['REB']>=10)| \\\n",
    "          (allplayerGameLogs['AST']>=10) & (allplayerGameLogs['BLK']>=10) & (allplayerGameLogs['REB']>=10)| \\\n",
    "          (allplayerGameLogs['PTS']>=10) & (allplayerGameLogs['STL']>=10) & (allplayerGameLogs['AST']>=10)| \\\n",
    "          (allplayerGameLogs['STL']>=10) & (allplayerGameLogs['AST']>=10) & (allplayerGameLogs['REB']>=10)\n",
    "    allplayerGameLogs['TriBL']= ttt\n",
    "    allplayerGameLogs['FanPTs'] = 3.5 * allplayerGameLogs['FG3M'] + 1*allplayerGameLogs['FTM'] \\\n",
    "    + 2*(allplayerGameLogs['FGM']-allplayerGameLogs['FG3M']) \\\n",
    "    + 1.25*allplayerGameLogs['REB']+1.5*allplayerGameLogs['AST'] \\\n",
    "    + 2*allplayerGameLogs['STL']+ 2*allplayerGameLogs['BLK'] \\\n",
    "    + 1.5*allplayerGameLogs['DouBL'] + 3*allplayerGameLogs['TriBL'] \\\n",
    "    - 0.5*allplayerGameLogs['TOV']\n",
    "    allplayerFantasyGameLogs = allplayerGameLogs.set_index('GAME_DATE')\n",
    "    allplayerFantasyGameLogs = allplayerFantasyGameLogs.sort_index(axis=0)\n",
    "\n",
    "    #data cleaning 2: make sure the players info we collected correspond to our player_id list.\n",
    "    allplayerFantasyGameLogs = pd.merge(allplayerFantasyGameLogs.reset_index(), playid_df[['playerId' \\\n",
    "         ,'fullName']], left_on='Player_ID',right_on='playerId', how='left')\n",
    "    del allplayerFantasyGameLogs['playerId']\n",
    "\n",
    "    #data cleaning 3: add position information for each player\n",
    "    with open('../Data/allPlayerBios.pickle', 'rb') as handle:\n",
    "      playerBios = pickle.load(handle)\n",
    "    allplayerFantasyGameLogs = pd.merge(allplayerFantasyGameLogs,playerBios[['PERSON_ID','position1']], left_on='Player_ID', \\\n",
    "                                    right_on='PERSON_ID', how='left')\n",
    "    del allplayerFantasyGameLogs['PERSON_ID']\n",
    "\n",
    "    #data cleaning 4: add team information for each player\n",
    "    allplayerFantasyGameLogs['Team'] = allplayerFantasyGameLogs['MATCHUP'].map(lambda x: x.split(' ')[0])\n",
    "    allplayerFantasyGameLogs['OpponentTeam'] = allplayerFantasyGameLogs['MATCHUP'].map(lambda x: x.split(' ')[2])\n",
    "    allplayerFantasyGameLogs['HomeGame'] = allplayerFantasyGameLogs['MATCHUP'].map(lambda x: 0 if x.split(' ')[1]=='@' else 1)\n",
    "\n",
    "    #data cleaning 5: Fix some missing values\n",
    "    allplayerFantasyGameLogs.loc[(allplayerFantasyGameLogs.fullName.isnull()) & (allplayerFantasyGameLogs.Player_ID==2403),'fullName'] = 'Nene Hilario'\n",
    "    \n",
    "    return allplayerFantasyGameLogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allplayerFantasyGameLogs = data_cleaner(allplayerGameLogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/allplayerFantasyGameLogs_0313.pickle', 'wb') as handle:\n",
    "  pickle.dump(allplayerFantasyGameLogs, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clean it up to Player Features/Stats Table for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allplayerFantasyGameLogs['GameMonth'] = allplayerFantasyGameLogs['GAME_DATE'].map(lambda dd: dd.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allplayerFantasyGameLogs.set_index('GAME_DATE', inplace=True)\n",
    "\n",
    "def aggr(group):\n",
    "    test_df = pd.DataFrame()    \n",
    "    test_df['LastFanPTs'] = group['FanPTs'][-1:]\n",
    "    test_df['AvgFanPTs'] = group['FanPTs'].mean()\n",
    "    test_df['AvgPTS'] = group['PTS'].mean()\n",
    "    test_df['LastPT'] = group['PTS'][-1:]\n",
    "    test_df['AvgMIN'] = group['MIN'].mean()\n",
    "    test_df['LastMIN'] = group['MIN'][-1:]\n",
    "    test_df['AvgFGM'] = group['FGM'].mean()\n",
    "    test_df['LastFGM'] = group['FGM'][-1:]\n",
    "    test_df['AvgFGA'] = group['FGA'].mean()\n",
    "    test_df['LastFGA'] = group['FGA'][-1:]\n",
    "    test_df['AvgFG3M'] = group['FG3M'].mean()\n",
    "    test_df['LastFG3M'] = group['FG3M'][-1:]\n",
    "    test_df['AvgFG3A'] = group['FG3A'].mean()\n",
    "    test_df['LastFG3A'] = group['FG3A'][-1:]\n",
    "    test_df['AvgREB'] = group['REB'].mean()\n",
    "    test_df['LastREB'] = group['REB'][-1:]\n",
    "    test_df['AvgAST'] = group['AST'].mean()\n",
    "    test_df['LastAST'] = group['AST'][-1:]\n",
    "    test_df['AvgSTL'] = group['STL'].mean()\n",
    "    test_df['AvgTOV'] = group['TOV'].mean() \n",
    "    test_df['LastTOV'] = group['TOV'][-1:]\n",
    "    test_df['AvgPF'] = group['PF'].mean()\n",
    "    test_df['LastPF'] = group['PF'][-1:]\n",
    "    test_df['AvgPLUS_MINUS'] = group['PLUS_MINUS'].mean()\n",
    "    test_df['LastPLUS_MINUS'] = group['PLUS_MINUS'][-1:]\n",
    "    #group['NumDouBL'] = group['DouBL'].sum()\n",
    "    #group['NumTriBL'] = group['TriBL'].sum()\n",
    "\n",
    "    test_df['Last3GameAvgFanPTs'] = group['FanPTs'][-3:].mean()\n",
    "    test_df['Last3GameAvgMIN'] = group['MIN'][-3:].mean()\n",
    "    test_df['Last3GameAvgPTS'] = group['PTS'][-3:].mean()\n",
    "    \n",
    "    num_team = len(group['Team'].unique())\n",
    "    if(num_team==1):\n",
    "        test_df['fullName'] = group['fullName'].unique()\n",
    "        test_df['Player_ID'] = group['Player_ID'].unique()\n",
    "        test_df['Team'] = group['Team'].unique()[0]\n",
    "        test_df['position1'] = group['position1'].unique()[0]\n",
    "    else:\n",
    "        test_df['fullName'] = group['fullName'].unique()\n",
    "        test_df['Player_ID'] = group['Player_ID'].unique()\n",
    "        test_df['Team'] = group['Team'].unique()[num_team-1]\n",
    "        test_df['position1'] = group['position1'].unique()       \n",
    "    \n",
    "    return(test_df)\n",
    "    \n",
    "def aggr_stats(date,allplayerFantasyGameLogs):\n",
    "    interest_columns = ['fullName','Player_ID','Team','position1','MIN','PTS','FGM','FGA', 'FG3M','FG3A', \\\n",
    "                        'REB','AST','STL','TOV','PF','PLUS_MINUS','DouBL','TriBL','FanPTs']\n",
    "    tmp = allplayerFantasyGameLogs.ix['2015-10-27':date]\n",
    "    \n",
    "    playerID_tmp = tmp.reset_index().copy()\n",
    "    tmp.grouped = playerID_tmp[interest_columns].groupby('Player_ID')\n",
    "    Newdf = pd.DataFrame()\n",
    "    ids = playerID_tmp['Player_ID'].unique()\n",
    "    \n",
    "    for id in ids:\n",
    "        group = tmp.grouped.get_group(id)\n",
    "        df = aggr(group)\n",
    "        Newdf = pd.concat([Newdf,df],axis=0)\n",
    "    \n",
    "    bins = [-10, 10, 20, 30, 40, 100]\n",
    "    group_names = ['benchPlayer','belowAvg','average','advanced','top']\n",
    "    Newdf['Rank']= pd.cut(Newdf['AvgFanPTs'],bins,labels=group_names)\n",
    "    \n",
    "    return(Newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggr_teamVSteam(group):\n",
    "        group['TeamStdVSFanPTs'] = group['FanPTs'].std()\n",
    "        group['TeamAvgVSFanPTs'] = group['FanPTs'].mean()\n",
    "        group['TeamMaxVSFanPTs'] = group['FanPTs'].max()\n",
    "        return group\n",
    "\n",
    "def aggr_team(group):\n",
    "        group['TeamStdFanPTs'] = group['TeamStdVSFanPTs'].mean()\n",
    "        group['TeamAvgFanPTs'] = group['TeamAvgVSFanPTs'].mean()\n",
    "        group['TeamMaxFanPTs'] = group['TeamMaxVSFanPTs'].mean()\n",
    "        return group    \n",
    "\n",
    "def generate_team_features(playerGameLogs, playerFeatureTable, date):\n",
    "    tmp = playerGameLogs['2015-10-27': date]\n",
    "    tmp = tmp.reset_index()\n",
    "    bad_players = playerFeatureTable[playerFeatureTable.Rank=='benchPlayer']['Player_ID']\n",
    "    interest_cols = ['fullName','Player_ID','Team','OpponentTeam','position1','FanPTs','MIN']\n",
    "    tmp = tmp[interest_cols]\n",
    "    tmp = tmp[~tmp['Player_ID'].isin(bad_players)]\n",
    "    \n",
    "    newdf = tmp.copy()\n",
    "    newdf_grouped = newdf.groupby(['Team','OpponentTeam'])\n",
    "        \n",
    "    Newdf = newdf_grouped.apply(aggr_teamVSteam)\n",
    "    Newdf.drop(['fullName','Player_ID','MIN','FanPTs','position1'],inplace=True,axis=1)\n",
    "    Newdf.drop_duplicates(['Team','OpponentTeam'],inplace=True)\n",
    "    \n",
    "    Newdf.drop('OpponentTeam',axis=1,inplace=True)\n",
    "    \n",
    "    Newdf2 = Newdf.copy()\n",
    "    Newdf2_grouped = Newdf2.groupby('Team')\n",
    "    \n",
    "    Newdf_overall = Newdf2_grouped.apply(aggr_team)\n",
    "    Newdf_overall.drop(['TeamStdVSFanPTs','TeamAvgVSFanPTs','TeamMaxVSFanPTs'],inplace=True,axis=1)\n",
    "    Newdf_overall.drop_duplicates('Team',inplace=True)\n",
    "    \n",
    "    return(Newdf_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_y(df):\n",
    "    # list comprehension of the cols that end with '_y'\n",
    "    to_drop = [x for x in df if x.endswith('_y')]\n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "def rename_x(df):\n",
    "    for col in df:\n",
    "        if col.endswith('_x'):\n",
    "            df.rename(columns={col:col.rstrip('_x')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_trainingdata(data):\n",
    "    data['Rank_dup'] = data['Rank']\n",
    "    data = data[data.Rank!='benchPlayer']\n",
    "    var_to_encode = ['Team','OpponentTeam','position1','HomeGame','Rank','GameMonth']\n",
    "    data = pd.get_dummies(data, columns=var_to_encode)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(train_date): #format like'2/10/2016' \n",
    "    train_date_index = pd.date_range(start='11/10/2015', end=train_date, freq='D')\n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    alldates = allplayerFantasyGameLogs.index\n",
    "    trydates = pd.date_range(start='10/27/2015', end='3/12/2016', freq='D') #need to adjust the end data for a specific training\n",
    "    s = set(alldates)\n",
    "    nodates = [x for x in trydates if x not in s]\n",
    "    \n",
    "    for idx in train_date_index:\n",
    "        tmp_idx = idx+1\n",
    "        if tmp_idx not in nodates and idx not in nodates:\n",
    "            #aggregate the statistics from players -> player-level features\n",
    "            trainLogs = allplayerFantasyGameLogs.ix['2015-10-27':idx]\n",
    "            train_player_df = aggr_stats(idx,trainLogs)   \n",
    "            #next we need to collect the player's next game Fantasy Points.\n",
    "            next_date = idx + 1\n",
    "            tmpLogs = allplayerFantasyGameLogs[['fullName', 'Player_ID','Team','OpponentTeam','HomeGame','FanPTs','GameMonth']].ix[next_date]\n",
    "            tmpLogs.rename(columns={'FanPTs':'NewGameFanPTs'},inplace=True)\n",
    "            #join the tmpLogs and player festure table by Player_ID, which is based on the players on a new game day\n",
    "            newgame_df = pd.merge(tmpLogs,train_player_df,how='inner',on='Player_ID')\n",
    "            drop_y(newgame_df)\n",
    "            rename_x(newgame_df)\n",
    "\n",
    "            #get the team features table \n",
    "            train_team_df = generate_team_features(allplayerFantasyGameLogs, train_player_df, idx)\n",
    "            newgame_df = pd.merge(newgame_df,train_team_df,how='left',on='Team')\n",
    "            data = pd.concat([data,newgame_df],axis=0)\n",
    "    \n",
    "    data = clean_trainingdata(data)\n",
    "    target='NewGameFanPTs'\n",
    "    predictors = [x for x in data.columns if x not in [target]]\n",
    "    \n",
    "    X_train = data[predictors]\n",
    "    y_train = data[target]  \n",
    "    \n",
    "    train_df,test_df,y_train,y_test = cross_validation.train_test_split(X_train,y_train,test_size=0.3,random_state=1)\n",
    "    return(train_df,test_df,y_train,y_test) \n",
    "#actually, the test_df is the validation set to control overfitting for our models. \n",
    "#The \"real\" test_set is only the games on a new day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df,test_df,y_train,y_test = get_train_test('3/11/2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fullName',\n",
       " u'Player_ID',\n",
       " 'LastFanPTs',\n",
       " 'AvgFanPTs',\n",
       " 'AvgPTS',\n",
       " 'LastPT',\n",
       " 'AvgMIN',\n",
       " 'LastMIN',\n",
       " 'AvgFGM',\n",
       " 'LastFGM',\n",
       " 'AvgFGA',\n",
       " 'LastFGA',\n",
       " 'AvgFG3M',\n",
       " 'LastFG3M',\n",
       " 'AvgFG3A',\n",
       " 'LastFG3A',\n",
       " 'AvgREB',\n",
       " 'LastREB',\n",
       " 'AvgAST',\n",
       " 'LastAST',\n",
       " 'AvgSTL',\n",
       " 'AvgTOV',\n",
       " 'LastTOV',\n",
       " 'AvgPF',\n",
       " 'LastPF',\n",
       " 'AvgPLUS_MINUS',\n",
       " 'LastPLUS_MINUS',\n",
       " 'Last3GameAvgFanPTs',\n",
       " 'Last3GameAvgMIN',\n",
       " 'Last3GameAvgPTS',\n",
       " 'TeamStdFanPTs',\n",
       " 'TeamAvgFanPTs',\n",
       " 'TeamMaxFanPTs',\n",
       " 'Rank_dup',\n",
       " u'Team_ATL',\n",
       " u'Team_BKN',\n",
       " u'Team_BOS',\n",
       " u'Team_CHA',\n",
       " u'Team_CHI',\n",
       " u'Team_CLE',\n",
       " u'Team_DAL',\n",
       " u'Team_DEN',\n",
       " u'Team_DET',\n",
       " u'Team_GSW',\n",
       " u'Team_HOU',\n",
       " u'Team_IND',\n",
       " u'Team_LAC',\n",
       " u'Team_LAL',\n",
       " u'Team_MEM',\n",
       " u'Team_MIA',\n",
       " u'Team_MIL',\n",
       " u'Team_MIN',\n",
       " u'Team_NOP',\n",
       " u'Team_NYK',\n",
       " u'Team_OKC',\n",
       " u'Team_ORL',\n",
       " u'Team_PHI',\n",
       " u'Team_PHX',\n",
       " u'Team_POR',\n",
       " u'Team_SAC',\n",
       " u'Team_SAS',\n",
       " u'Team_TOR',\n",
       " u'Team_UTA',\n",
       " u'Team_WAS',\n",
       " u'OpponentTeam_ATL',\n",
       " u'OpponentTeam_BKN',\n",
       " u'OpponentTeam_BOS',\n",
       " u'OpponentTeam_CHA',\n",
       " u'OpponentTeam_CHI',\n",
       " u'OpponentTeam_CLE',\n",
       " u'OpponentTeam_DAL',\n",
       " u'OpponentTeam_DEN',\n",
       " u'OpponentTeam_DET',\n",
       " u'OpponentTeam_GSW',\n",
       " u'OpponentTeam_HOU',\n",
       " u'OpponentTeam_IND',\n",
       " u'OpponentTeam_LAC',\n",
       " u'OpponentTeam_LAL',\n",
       " u'OpponentTeam_MEM',\n",
       " u'OpponentTeam_MIA',\n",
       " u'OpponentTeam_MIL',\n",
       " u'OpponentTeam_MIN',\n",
       " u'OpponentTeam_NOP',\n",
       " u'OpponentTeam_NYK',\n",
       " u'OpponentTeam_OKC',\n",
       " u'OpponentTeam_ORL',\n",
       " u'OpponentTeam_PHI',\n",
       " u'OpponentTeam_PHX',\n",
       " u'OpponentTeam_POR',\n",
       " u'OpponentTeam_SAC',\n",
       " u'OpponentTeam_SAS',\n",
       " u'OpponentTeam_TOR',\n",
       " u'OpponentTeam_UTA',\n",
       " u'OpponentTeam_WAS',\n",
       " 'position1_C',\n",
       " 'position1_PF',\n",
       " 'position1_PG',\n",
       " 'position1_SF',\n",
       " 'position1_SG',\n",
       " 'HomeGame_0',\n",
       " 'HomeGame_1',\n",
       " 'Rank_advanced',\n",
       " 'Rank_average',\n",
       " 'Rank_belowAvg',\n",
       " 'Rank_top',\n",
       " 'GameMonth_1',\n",
       " 'GameMonth_2',\n",
       " 'GameMonth_3',\n",
       " 'GameMonth_11',\n",
       " 'GameMonth_12']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train,columns=['NewGameFanPTs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test,columns=['NewGameFanPTs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('../Data/train_df_0313.csv',index=False)\n",
    "y_train.to_csv('../Data/y_train_0313.csv',index=False)\n",
    "test_df.to_csv('../Data/valid_df_0313.csv',index=False)\n",
    "y_test.to_csv('../Data/y_valid_0313.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
